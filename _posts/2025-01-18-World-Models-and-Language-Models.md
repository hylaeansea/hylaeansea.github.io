---
layout: post
title:  "World Models and Language Models, a Philosophy"
date:   2025-01-18 08:17:00 +0000
categories: blog
---

<style>
.prompt-box {
    border: 2px solidrgb(54, 56, 54); 
    padding: 10px; 
    border-radius: 5px; 
    background-color:rgb(215, 191, 255); 
    box-shadow: 2px 2px 5px rgba(0, 0, 1, 0.1);
}
.chatgpt-4o-box {
    border: 2px solidrgb(54, 56, 54); 
    padding: 10px; 
    border-radius: 5px; 
    background-color:rgb(202, 235, 194); 
    box-shadow: 2px 2px 5px rgba(0, 0, 1, 0.1);
}
.llama-box {
    border: 2px solidrgb(54, 56, 54); 
    padding: 10px; 
    border-radius: 5px; 
    background-color:rgb(209, 209, 209); 
    box-shadow: 2px 2px 5px rgba(0, 0, 1, 0.1);
}
.claude-box {
    border: 2px solidrgb(54, 56, 54); 
    padding: 10px; 
    border-radius: 5px; 
    background-color:rgb(187, 135, 116); 
    box-shadow: 2px 2px 5px rgba(0, 0, 1, 0.1);
}

</style>



# Abstract


![Computable Policy]({{ site.baseurl }}/assets/images/DALL·E_2025-01-18_11.27.13-A_futuristic_and_realistic_scene_depicting_the_concept_of_computable_policy.webp) 
*Image generated with DALL·E; prompt: make a futuristic but realistic image that exemplifies "computable policy" as you have just described*


# Introduction

Many of the incredible advances in AI over the last few years have come as the result of connecting external tools to large language models (LLMs). Tools in the form of:

- [OpenAI Code Interpreter and IDEs](https://platform.openai.com/docs/assistants/tools)
- [LangChain access to APIs](https://python.langchain.com/docs/introduction/)
- [Nvidia World Foundation Models](https://blogs.nvidia.com/blog/cosmos-world-foundation-models/)
- and many many others,

...provide LLMs with external simulations, application programming interfaces (APIs), data, and computation that doesn't have to be learned as part of the base model training or fine tuning. This allows for the LLM to access a much more diverse and rich set of data and ideas than it would otherwise have access to in it's training corpus. In fact, this idea of LLMs as a sort of "glue" for various tasks, data sets, and APIs form the foundational idea of Agentic AI. 

This approach however, has seen most of its success in domains that are readily computable such as access to APIs, physics simulations, or database queries. The very nature of "world models" is that their response can be calculated from physics models of the objects and agents in the virtual world. Another term for these are "Digital Twins" that simulate the behavior of a physical factory, smart city, or other physical system for example. I believe the reason for this rests in the fact that while they can be computationally expensive, we have really good mathematical models for many of these physical systems and thus they lend themselves to computation. This leads to my first conjecture about AIs and World Models: 

**Conjecture 1:** Large Language Models often excel at tasks where the accuracy of their output is relatively easy to verify. Testing whether code compiles, having a bilingual human verify a translation, determining if re-written prose sounds better, or a generated poem conforms to rhyme and meter, are all tasks that can be done by humans or verified computationally with relative ease. This makes reinforcement learning more tractable because we can plainly see (or test) if the output is correct.

However, there still exist a wide range of domains where it is more difficult, more subjective, and not as obvious to verify or test the correctness of an LLM output. It is not as easy, for example, to verify that a public policy recommendation is going to have the desired affect, or if a post on social media is going to foster civil discussion or cause harm, or if a particular social program is going to reach the desired people. These problems can't be "complied" as computer code can, these problems can sound coherent and well thought out, but then have secondary effects that are unintended. LLM generated public policy recommendations can be very detailed (especially with more and more detailed prompts as we will see below) and read very eloquently, however they will have been generated by "next token prediction" by a transformer network rather than generated by a simulation of, or contemplation and deliberation on, the outcome of the policy. Furthermore, if we can somehow make these foundations of society (law, policy, regulations, cultural text) more computable, we could auto generate massive amounts of training data to bake in this computable policy knowledge into the language models at training time. This could result in a future where our frontier AI models have computational knowledge of complex social, cultural, social, and civic domains. 

Therefore, the foundational motivation for this work is to answer the question:

***Can we make policy computable?***

# Prior Work

This idea of social, economic, policy, civic, and society simulation is not novel and there are many (many) examples where complex computational models have been used to guide public policy and decision making:

- *John Sterman* (2000). Business Dynamics: System Thinking and Modeling for a Complex World. New York: McGraw-Hill.
- *Stephen Wolfram (2016), [Computational Law, Symbolic Discourse and the AI Constitution](https://writings.stephenwolfram.com/2016/10/computational-law-symbolic-discourse-and-the-ai-constitution/)
- *Edward J Walters* (2019). [Data Driven Law](https://www.routledge.com/Data-Driven-Law-Data-Analytics-and-the-New-Legal-Services/Walters/p/book/9781498766654)
- [MIT Computable Law Project](https://www.media.mit.edu/articles/a-perspective-on-legal-algorithms/)

...and of course many others. So this idea is not new, and in fact has been pontificated on by some computing and legal luminaries. I do think though, that as AIs in general and LLMs in particular continue to find use in more and more domains in our society, that highlighting the particular shortcomings of the frontier models for policy generation, and providing a philosophy on how we can remedy them through this approach is important. Through this work I also want to explore two particular avenues that I think are relatively novel and warrant further work: 

1) **Can an LLM be used to create the "world model" and then by running the model, learn knowledge it wouldn't otherwise have?** That is, does an LLM have the internal knowledge to (with clever prompting) create the computational world model, create configurations of specific runs of the model, and then learn from the output? This would hint at "weak-to-strong-***self*** generalization" as an adaptation of [Weak-to-Strong Generalization](https://openai.com/index/weak-to-strong-generalization/) if the LLM can create, and then learn from a computational world model. This **self** generalization may have alignment implications as we more fully explore agentic systems. 

2) **Can we use computational policy and LLMs to design policy or ideas around increasing AI equality in our society?** 2025 is turning out to be a pivotal year for public policy and AI technological development each individually, but this might be an especially important year for the intersection of these two domains. The adoption, distribution, and development of AI systems by different slices of society in the near term, might have feedback effects that entrench these early distributions of the technology for a long time to come. It might be especially important then to leverage these rapidly advancing technologies to design AI policy and regulation that most closely align with the values of freedom, equality, and democracy. 

# Methodology

In this paper, I will explore these three questions: 

1. Can we make policy computable?
2. Can an LLM generate its own world model for policy computation? and 
3. Can we use LLMs and this generated world model to explore or design policy to increase the adoption of AI tech and hence digital and AI literacy and equality?

To explore these questions, I will break my investigation into the following steps:

1. First I will explore current AI models (gpt4o, claude 3.5 haiku, and ollama3.1:8b) capability in designing a policy to increase the adoption of AI. I will examine the qualitative features of the models at progressively higher levels of detail in the policy. This initial method of model comparison is illustrated in the following figure:

![LLM Policy Generation]({{ site.baseurl }}/assets/images/LLM_policy_generation_01.png)
*Figure 1: LLM Based Policy Generation and Iteration*

2. Next, I will also compare the model responses for different situations (AI education policy for two different municipalities) which I believe should cause substantive differences in the policy recommendations and outcomes. By comparing the different social situations, I will draw (again qualitative) comparisons between these. My hypothesis in this, is that while detailed and specific, there will be few differences between amongst the models for the same prompt, as well as few differences between the responses for the two municipalities. This method is illustrated below: 

![LLM Policy Generation]({{ site.baseurl }}/assets/images/LLM_policy_generation_02.png)
*Figure 2: LLM Based Policy Generation for Specific Municipalities*

3. Next, I will explore using a single LLM to generate a policy world model to simulate AI adoption policy impacts. For this I will be using a rather simple toy model developed in [agentpy](https://agentpy.readthedocs.io/en/latest/). Agentpy is a python module for simulating simple agent-based networks. I should note that these are not AI agents, but rather simple rules based agents. Even given this consideration, interesting and emergent behavior is often observed in models developed in agentpy. I will heavily leverage LLMs (specifically gpt4o and o1) in the creation of a progressively more complex agent based world model. This process is pictorially shown below.

![LLM generated world model]({{ site.baseurl }}/assets/images/LLM_generated_world_model_01.png)
*Figure 3: LLM Generated World Model*

4. After the world model is built, I will leverage LLMs to generate the starting conditions and parameters of the agentpy simulation, as well as interpret the numeric results in a qualitative natural language way. My hypothesis for this step is that the LLM is capable of generating an agent based world model simulation, from which it can gain knowledge that it doesn't have in its base model. This step is illustrated below:

![New Knowledge]({{ site.baseurl }}/assets/images/New_Knowledge.png)
*Figure 4: New Knowledge is potentially generated from the World Model interacting with the Language Model*


My hope is that through these steps I can demonstrate how LLMs can be used to not only generate rich world models for public policy recommendation and analysis, but also by using **AI tech adoption** as the exemplar policy in the above steps, develop some intuition about how we might adopt policy to increase that adoption. 

A quick disclaimer: I have only interest but no backround in public policy, or public tech policy. Furthermore, I will be exploring only toy models that are not fully descriptive of the complex dynamics, economics, and interactions in public policy analysis. Nevertheless, I think that this project serves as an interesting jumping off point for world model generation in this way, I if I can motivate the true public policy and social computing professionals to think about some of my proposed philosophy this will be a success. With that...*lets go!*

# Results

## Generating Public Policy with LLMs

In this first step I generated public policy recommendations at different levels of detail and evaluated the results for their qualitative strengths and weaknesses. 

![LLM Policy Generation]({{ site.baseurl }}/assets/images/LLM_policy_generation_01.png)
*Figure 1: LLM Based Policy Generation and Iteration*


<div class="prompt-box">
<b>Prompt</b>: What are key elements of a public policy to maximize the uptake and adoption of AI technology by the maximum number of people? Be Specific.
</div>

Some example responses include:

<div class="chatgpt-4o-box">
    <b>ChatGPT 4o</b>: Its response focuses on Education, Accessibility, Infrastructure, Trust, Public Awareness, and other suggestions. These categories have a couple of simple bullet points, however this response remains high level.

<details>
  <summary>
    Click here for full text of response
  </summary>
<hr>
Key Elements of a Public Policy to Maximize AI Adoption
<br>
<h3>1. Education and Skills Development</h3>
<ul>
    <li><strong>AI Literacy Programs:</strong> Introduce AI literacy in school curricula and adult education programs to demystify the technology.</li>
    <li><strong>Reskilling Initiatives:</strong> Provide training and certifications in AI-related skills for workers displaced by automation.</li>
    <li><strong>Community Workshops:</strong> Offer free or low-cost workshops and online courses tailored to different demographics, especially underserved communities.</li>
</ul>

<h3>2. Accessibility and Affordability</h3>
<ul>
    <li><strong>Subsidies for AI Tools:</strong> Provide financial assistance or tax incentives for small businesses and individuals to purchase AI software and hardware.</li>
    <li><strong>Open-Source Initiatives:</strong> Promote the development and availability of open-source AI tools and platforms.</li>
    <li><strong>Digital Inclusion Programs:</strong> Expand access to the internet and devices in rural and low-income areas.</li>
</ul>

<h3>3. Infrastructure Development</h3>
<ul>
    <li><strong>High-Speed Internet:</strong> Invest in nationwide broadband infrastructure to ensure equitable access.</li>
    <li><strong>Cloud Computing Resources:</strong> Provide access to shared computing resources, such as public AI supercomputing hubs.</li>
    <li><strong>Data Sharing Frameworks:</strong> Create secure and ethical data-sharing platforms to support AI innovation.</li>
</ul>

<h3>4. Trust and Ethics</h3>
<ul>
    <li><strong>Regulation of Bias and Fairness:</strong> Enforce clear guidelines to reduce bias in AI algorithms and ensure fair outcomes.</li>
    <li><strong>Transparent AI Policies:</strong> Mandate that organizations disclose how AI systems make decisions.</li>
    <li><strong>Consumer Protections:</strong> Develop robust policies for data privacy, security, and accountability.</li>
</ul>

<h3>5. Financial Incentives</h3>
<ul>
    <li><strong>Tax Credits:</strong> Offer tax benefits to businesses that adopt AI technologies for productivity or innovation.</li>
    <li><strong>Grants for Startups:</strong> Provide funding to AI startups and small businesses to encourage experimentation and deployment.</li>
    <li><strong>Public-Private Partnerships:</strong> Foster collaborations between government, academia, and industry to lower the costs of AI adoption.</li>
</ul>

<h3>6. Public Awareness Campaigns</h3>
<ul>
    <li><strong>Showcase Success Stories:</strong> Highlight how AI is being used to solve real-world problems in diverse fields such as healthcare, agriculture, and education.</li>
    <li><strong>Address Fears:</strong> Run campaigns that address concerns about job displacement and AI risks, focusing on its potential benefits.</li>
</ul>

<h3>7. Sector-Specific Support</h3>
<ul>
    <li><strong>Tailored Adoption Programs:</strong> Develop sector-specific AI adoption guidelines and tools (e.g., for healthcare, education, manufacturing).</li>
    <li><strong>Incubators and Sandboxes:</strong> Establish environments where businesses can test AI solutions under regulatory guidance.</li>
</ul>

<h3>8. Inclusive Design and Participation</h3>
<ul>
    <li><strong>Localized Solutions:</strong> Support AI development tailored to local languages, cultural norms, and regional needs.</li>
    <li><strong>Community Involvement:</strong> Involve diverse stakeholders, including marginalized communities, in the design and implementation of AI policies.</li>
</ul>

<h3>9. Incentivizing Research and Development</h3>
<ul>
    <li><strong>Academic Funding:</strong> Increase funding for AI research in public universities and institutions.</li>
    <li><strong>Cross-Border Collaboration:</strong> Partner with international entities to share knowledge and resources.</li>
</ul>

<h3>10. Monitoring and Evaluation</h3>
<ul>
    <li><strong>Impact Assessment Frameworks:</strong> Continuously evaluate the societal and economic impact of AI adoption.</li>
    <li><strong>Feedback Mechanisms:</strong> Set up channels for public feedback to iteratively improve AI policies.</li>
</ul>

<h3>Implementation Strategy</h3>
<ul>
    <li><strong>Pilot Programs:</strong> Roll out pilot projects in targeted communities to test policies and adjust based on outcomes.</li>
    <li><strong>Scalable Models:</strong> Focus on scalable models for AI deployment to maximize reach.</li>
</ul>

<h3>Legal and Policy Support</h3>
<ul>
    <li><strong>Legal Frameworks:</strong> Simplify compliance requirements for AI technology adoption while maintaining ethical standards.</li>
    <li><strong>AI Ombudsman:</strong> Create an independent body to address grievances and ensure fair AI implementation.</li>
</ul>


</details>

</div>

<div class="llama-box">

<b>llama3.1:8b</b> provided fewer focus elements than <b>o4</b>, however they were similar: Education, Infrastructure, Regulation, and Economic Incentives. Similarly to <b>4o</b>, <b>llama3.1:8b</b> remains at a high level without much detail.

<details>
  <summary>
    Click here for full text of response
  </summary>
    <hr>
    To maximize the uptake and adoption of AI technology by the maximum number of people, a public policy should include the following key elements:
    <br>
    <h3><strong>I. Infrastructure and Accessibility</strong></h3>
    <ol>
        <li><strong>Universal Broadband</strong>: Ensure that all households have access to high-speed internet (at least 100 Mbps) to facilitate AI-powered applications.</li>
        <li><strong>Digital Literacy Training</strong>: Provide training programs for individuals to develop basic digital skills, including understanding of AI concepts and how to use AI-enabled devices.</li>
        <li><strong>Accessibility Standards</strong>: Implement accessibility standards for AI systems, ensuring that they can be used by people with disabilities.</li>
    </ol>

    <h3><strong>II. Education and Awareness</strong></h3>
    <ol>
        <li><strong>AI Education in Schools</strong>: Integrate AI education into school curricula, starting from primary level, to foster a generation of AI-literate individuals.</li>
        <li><strong>Public Awareness Campaigns</strong>: Launch public awareness campaigns to educate citizens about the benefits, risks, and applications of AI technology.</li>
        <li><strong>Research Grants</strong>: Provide research grants for academia and industry to develop AI-related educational materials and programs.</li>
    </ol>

    <h3><strong>III. Regulations and Governance</strong></h3>
    <ol>
        <li><strong>Clear AI Regulations</strong>: Establish clear regulations and guidelines for AI development, deployment, and use in various sectors (e.g., healthcare, finance).</li>
        <li><strong>Data Protection and Privacy</strong>: Strengthen data protection laws and regulations to safeguard citizens' personal data used by AI systems.</li>
        <li><strong>Transparency and Accountability</strong>: Mandate transparency in AI decision-making processes and hold developers accountable for AI-related errors or harm.</li>
    </ol>

    <h3><strong>IV. Economic and Social Incentives</strong></h3>
    <ol>
        <li><strong>Tax Incentives</strong>: Offer tax incentives to businesses that invest in AI research, development, and deployment.</li>
        <li><strong>Job Training Programs</strong>: Develop job training programs to upskill workers in areas where AI is transforming industries (e.g., manufacturing, customer service).</li>
        <li><strong>Social Benefits</strong>: Provide social benefits, such as subsidies or vouchers, for low-income individuals who want to access AI-enabled services.</li>
    </ol>

    <h3><strong>V. Collaboration and Partnerships</strong></h3>
    <ol>
        <li><strong>Public-Private Partnerships</strong>: Foster partnerships between government agencies, industry leaders, and academia to drive AI innovation and adoption.</li>
        <li><strong>AI Ecosystem Development</strong>: Encourage the development of AI ecosystems in various regions, promoting collaboration among startups, researchers, and businesses.</li>
        <li><strong>Global Cooperation</strong>: Engage in international collaborations to establish global standards for AI development, deployment, and use.</li>
    </ol>

    <h3><strong>VI. Monitoring and Evaluation</strong></h3>
    <ol>
        <li><strong>Impact Assessment</strong>: Conduct regular impact assessments to evaluate the effectiveness of public policies on AI adoption and usage.</li>
        <li><strong>Data Collection</strong>: Establish a data collection framework to monitor AI-related trends, challenges, and best practices.</li>
        <li><strong>Continuous Review and Update</strong>: Regularly review and update policies as new evidence emerges or as AI technology evolves.</li>
    </ol>

    <p>By incorporating these key elements, a public policy can effectively support the widespread adoption of AI technology and maximize its benefits for society as a whole.</p>
</details>
</div>

These responses are coherent, have good diverse suggestions, and seem like they would be good public policy recommendations to increase the general public's understanding and use of emerging AI. However, they lack specific policy details like funding levels, distribution of tech and benefits amongst society, the ability to deal with specific alignment issues, and the relationship between AI companies, the public, and regulating bodies. This is not a critique of these initial responses, and the next logical prompt would be to focus on a specific area of the policy and refine the details.

If we look at prompts to focus on AI education but for two different cities, we see largely similar responses.

<div class="prompt-box">
provide a specific policy for the increasing of education on AI for <b>Denver</b> Public Schools, focus on program cost, student admittance, whether it should focus on low and middle income schools, use of other resources in the community and provide hurdles to this implementation, please write the response in html with the highest level of header being h2
</div>

<div class="chatgpt-4o-box">
<b>ChatGPT-4o</b> - Policy for Expanding AI Education in Denver Public Schools
<details>
<summary>
Cost, Admission, Community Resources, Hurdles
</summary>
    <h3>Program Cost</h3>
    <p>The estimated cost for the program is $2.5 million annually. This includes curriculum development, teacher training, purchasing technology (computers, AI software), and funding extracurricular activities such as AI clubs or hackathons. Additional funding will be allocated for partnerships with local tech companies and universities.</p>

    <h3>Student Admittance</h3>
    <p>Admission to the program will be open to all students in Denver Public Schools. However, priority will be given to students from low- and middle-income backgrounds to ensure equitable access to AI education. Outreach efforts will focus on underrepresented groups in STEM fields, including girls and minorities.</p>

    <h3>Focus on Low and Middle-Income Schools</h3>
    <p>The program will initially target low and middle-income schools where access to technology and advanced STEM education is limited. By addressing educational disparities, the program aims to bridge the digital divide and prepare students for future opportunities in AI-related fields.</p>

    <h3>Utilizing Community Resources</h3>
    <ul>
        <li><strong>Local Tech Companies:</strong> Collaborate with tech firms in Denver to provide mentorship, internships, and funding for resources.</li>
        <li><strong>Universities:</strong> Partner with the University of Colorado and other institutions to develop a robust AI curriculum and offer dual-enrollment courses.</li>
        <li><strong>Community Centers:</strong> Use existing community centers to host AI workshops and provide after-school programs.</li>
        <li><strong>Nonprofits:</strong> Work with nonprofit organizations focused on STEM education to secure grants and additional resources.</li>
    </ul>

    <h3>Hurdles to Implementation</h3>
    <ul>
        <li><strong>Funding:</strong> Securing sustainable funding may be challenging due to budget constraints and competing priorities within the school district.</li>
        <li><strong>Teacher Training:</strong> There may be a shortage of educators with the expertise to teach AI effectively, necessitating significant investment in professional development.</li>
        <li><strong>Infrastructure:</strong> Many schools, especially in low-income areas, may lack the necessary technology infrastructure to support AI education.</li>
        <li><strong>Community Buy-In:</strong> Gaining support from parents, teachers, and local stakeholders may require extensive outreach and demonstration of the program's value.</li>
        <li><strong>Equity Challenges:</strong> Ensuring equitable access and avoiding unintentional exclusion of marginalized groups will require careful planning and oversight.</li>
    </ul>
</details>
</div>

<div class="prompt-box">
provide a specific policy for the increasing of education on AI for <b>Boulder</b> Public Schools, focus on program cost, student admittance, whether it should focus on low and middle income schools, use of other resources in the community and provide hurdles to this implementation, please write the response in html with the highest level of header being h2
</div>

<div class="chatgpt-4o-box">
<b>ChatGPT-4o</b> - Policy for Expanding AI Education in Boulder Public Schools
<details>
<summary>
Cost, Admission, Equity, Community Resources, Hurdles
</summary>

    <h2>AI Education Policy for Boulder Public Schools</h2>

    <h3>Program Cost</h3>
    <p>
        The program is estimated to cost $500,000 annually, with funding allocated to teacher training, AI curriculum development, and equipment such as computers and software licenses. Grants from technology companies and state educational funds should be pursued to reduce the burden on the school district.
    </p>

    <h3>Student Admittance</h3>
    <p>
        The program should initially target middle and high school students with demonstrated interest in technology and science. Admission will be determined by teacher recommendations, application essays, and interest surveys to ensure students' commitment.
    </p>

    <h3>Focus on Low and Middle-Income Schools</h3>
    <p>
        The policy will prioritize low and middle-income schools to bridge the digital divide. Schools in these areas will receive additional resources, including outreach initiatives to inform students and parents about the benefits of AI education.
    </p>

    <h3>Use of Other Resources in the Community</h3>
    <p>
        Partnerships with local universities, tech companies, and libraries will provide additional support. These resources may include guest lectures, internships, AI-focused workshops, and access to advanced computing facilities.
    </p>

    <h3>Hurdles to Implementation</h3>
    <ul>
        <li><strong>Funding:</strong> Securing consistent funding from public and private sources could be challenging.</li>
        <li><strong>Teacher Training:</strong> Current staff may lack the expertise to teach AI concepts, requiring extensive professional development.</li>
        <li><strong>Curriculum Development:</strong> Crafting a relevant and engaging curriculum will take time and specialized knowledge.</li>
        <li><strong>Equity:</strong> Ensuring all students have access to necessary hardware and internet connectivity at home may be difficult.</li>
        <li><strong>Community Buy-In:</strong> Gaining support from parents, teachers, and administrators may require significant effort to highlight the program's benefits.</li>
    </ul>

    <p>
        Implementing AI education in Boulder Public Schools will require careful planning and collaboration with community partners. By addressing funding and training challenges while focusing on equity, the district can create a robust program that benefits students and prepares them for future careers.
    </p>

</details>

</div>
<br>

We can see from these responses to nearly identical prompts that there are possibly some relevant differences, like cost for the different sized populations, a slight difference in low and middle income emphasis, and some more detail (or at least different formatting) for the engagement of community resources. However, reflecting on my original conjecture:

* *How do we know how well these policies will work?*
* *What accounts for the differences between the policies for different municipalities?*
* *Is there a better way to bake this knowledge into our LLMs, rather than whole internet base training, followed by fine tuning and alignment?*
* In short: ***Can we make policy computable?***

This is merely a motivating example, and we need to spend a little time hypothesizing why computable policy might be useful.

## Why would computable policy be useful?

It is interesting to note that with all of the compute ability that our society possesses, the very structure, law, rules, regulations, and much of written culture is expressed as natural language. A quick internet search on computable policy reveal a handful of relatively modern examples (more on this below), however the most foundational structure of our society, legals system, economic policy, and social policy is defined in a language that does not lend itself to computation. Of course the main topic of this project is exploring Large Language Models and of course the tokenization and processing through transformer networks of natural language is a form of computation. However we are interested in how policies, laws, and regulations transform into economic benefit, equality, enhanced education, and justice, rather than the next tokens of text. 

**Conjecture 2:** By linking natural language policy statements with economic simulations, followed by expression of qualitative or quantitative expressions of value, we can create a training corpus of natural language prompts and responses in order to fine tune LLMs to learn knowledge gained from these simulations.

**Conjecture 3:** LLMs themselves, or agentic systems, can be used to generate these simulations and develop interfaces to specify the policy rules in code, run the simulation with variations on this input, and interpret results back as natural language. By having LLMs develop these external models of society and policy, they can learn knowledge that is not learned during model pre training.

## Existing work on computable policy and world models

Throughout my investigation for this project I have found many examples of connection

# Methods of Investigation

# Results

# Discussion

## What does this mean for safety

Talk about agentic and a diversity of specifically fine tuned models

# Future Work

## Ocean Biodiversity and Conservation

## Space Policy


